{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "golden-sitting",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"/home/raecker1/3DSSL/\")\n",
    "\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchio as tio\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import nibabel as nib\n",
    "from skimage.registration import optical_flow_tvl1\n",
    "from skimage.transform import warp\n",
    "print(torch.__version__)\n",
    "\n",
    "from selfsupervised2d.simclr.simclr_module import SimCLR\n",
    "from selfsupervised3d.simclr.transforms import SimCLRTrainDataTransform, SimCLREvalDataTransform\n",
    "from selfsupervised2d.simclr.dataset import SimCLR3DDataset, NakoIQADataset, NRUDataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3530ecc1",
   "metadata": {},
   "source": [
    "Init Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lyric-earth",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessings = tio.transforms.Compose([\n",
    "            tio.transforms.ZNormalization(),\n",
    "            tio.RescaleIntensity((-1, 1))\n",
    "        ])\n",
    "\n",
    "# UKB\n",
    "val_dataset = SimCLR3DDataset('/mnt/qdata/share/rakuest1/data/UKB/raw/abdominal_MRI/raw/', \"/home/raecker1/3DSSL/ukb_abdominal_val_keys.npy\",\n",
    "                    preprocessings, True)\n",
    "\n",
    "# NAKO\n",
    "nako_iqa_dataset = NakoIQADataset(\"/mnt/qdata/rawdata/NAKO_IQA/NAKO_IQA_nifti/\", preprocessings, suffix=\"bh_W_COMPOSED\")\n",
    "nako_iqa_dataset_deep = NakoIQADataset(\"/mnt/qdata/rawdata/NAKO_IQA/NAKO_IQA_nifti/\", preprocessings, suffix=\"fb_deep_W_COMPOSED\")\n",
    "\n",
    "# NRU\n",
    "# infixes: T1 STIR: _acq-t1tirmpmcoff_rec-wore_run-, T2 TSE: _acq-t2tsepmcoff_rec-wore_run-, \n",
    "# T1 MPRAGE: _acq-mpragepmcoff_rec-wore_run-, FLAIR: _acq-flairpmcoff_rec-wore_run-, \n",
    "# T2 STAR: _acq-t2starpmcoff_rec-wore_run-\n",
    "nru_dataset_still = NRUDataset(\"/home/raecker1/data/NRU/\", preprocessings, suffix=\"01_T1w\", infix='_acq-mpragepmcoff_rec-wore_run-')\n",
    "nru_dataset_nod = NRUDataset(\"/home/raecker1/data/NRU/\", preprocessings, suffix=\"02_T1w\", infix='_acq-mpragepmcoff_rec-wore_run-')\n",
    "nru_dataset_shake = NRUDataset(\"/home/raecker1/data/NRU/\", preprocessings, suffix=\"03_T1w\", infix = '_acq-mpragepmcoff_rec-wore_run-')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3062fd6",
   "metadata": {},
   "source": [
    "Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proper-struggle",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def load_slice(subj_idx, idx, noise=None):\n",
    "    if noise:\n",
    "        slc = noise(val_dataset[subj_idx])[\"data\"][\"data\"][0,:,:,idx]\n",
    "    else:\n",
    "        slc = val_dataset[subj_idx][\"data\"][\"data\"][0,:,:,idx]\n",
    "    #slc = np.pad(slc, ((0,0), (28,28)))\n",
    "    #slc = torch.from_numpy(slc)\n",
    "    return slc.unsqueeze(0)\n",
    "\n",
    "def load_slice_nako(subj_idx, idx, noise=None):\n",
    "    if noise:\n",
    "        slc = noise(nako_iqa_dataset[subj_idx])[\"data\"][\"data\"][0,20:-20,:224,idx].unsqueeze(0)\n",
    "    else:\n",
    "        slc = nako_iqa_dataset[subj_idx][\"data\"][\"data\"][0,20:-20,:224,idx].unsqueeze(0)\n",
    "    slc = torchvision.transforms.functional.resize(slc, [224, 224])\n",
    "    #slice = np.pad(slice, ((0,0), (28,28)))\n",
    "    #slice = torch.from_numpy(slice)\n",
    "    return slc\n",
    "\n",
    "def load_slice_nako_deep(subj_idx, idx, noise=None):\n",
    "    if noise:\n",
    "        slc = noise(nako_iqa_dataset_deep[subj_idx])[\"data\"][\"data\"][0,20:-20,:224,idx].unsqueeze(0)\n",
    "    else:\n",
    "        slc = nako_iqa_dataset_deep[subj_idx][\"data\"][\"data\"][0,20:-20,:224,idx].unsqueeze(0)\n",
    "    slc = torchvision.transforms.functional.resize(slc, [224, 224])\n",
    "    #slice = np.pad(slice, ((0,0), (28,28)))\n",
    "    #slice = torch.from_numpy(slice)\n",
    "    return slc\n",
    "\n",
    "\n",
    "def load_slice_nru_still(subj_idx, idx=None, pos=None, noise=None):\n",
    "    if noise:\n",
    "        if pos == 'middle':\n",
    "            print('using middle slice')\n",
    "            data = noise(nru_dataset_still[subj_idx])[\"data\"][\"data\"][0,:,:,:]\n",
    "            slc = data[:,:,data.shape[2]//2].unsqueeze(0)\n",
    "        elif idx:\n",
    "            print(f'using id {idx}')\n",
    "            slc = noise(nru_dataset_still[subj_idx])[\"data\"][\"data\"][0,:,:,idx].unsqueeze(0)\n",
    "        else:\n",
    "            raise ValueError(\"Please specify idx or pos\")\n",
    "    else:\n",
    "        if pos == 'middle':\n",
    "            print('using middle slice')\n",
    "            data = nru_dataset_still[subj_idx][\"data\"][\"data\"][0,:,:,:]\n",
    "            slc = data[:,:,data.shape[2]//2].unsqueeze(0)\n",
    "        elif idx:\n",
    "            print(f'using id {idx}')\n",
    "            slc = nru_dataset_still[subj_idx][\"data\"][\"data\"][0,:,:,idx].unsqueeze(0)\n",
    "        else:\n",
    "            raise ValueError(\"Please specify idx or pos\")\n",
    "    return slc\n",
    "\n",
    "\n",
    "def load_slice_nru_shake(subj_idx, idx=None, pos=None, noise=None):\n",
    "    if noise:\n",
    "        if pos == 'middle':\n",
    "            print('using middle slice')\n",
    "            data = noise(nru_dataset_shake[subj_idx])[\"data\"][\"data\"][0,:,:,:]\n",
    "            slc = data[:,:,data.shape[2]//2].unsqueeze(0)\n",
    "        elif idx:\n",
    "            print(f'using id {idx}')\n",
    "            slc = noise(nru_dataset_shake[subj_idx])[\"data\"][\"data\"][0,:,:,idx].unsqueeze(0)\n",
    "        else:\n",
    "            raise ValueError(\"Please specify idx [int] or pos ['middle']\")\n",
    "    else:\n",
    "        if pos == 'middle':\n",
    "            print('using middle slice')\n",
    "            data = nru_dataset_shake[subj_idx][\"data\"][\"data\"][0,:,:,:]\n",
    "            slc = data[:,:,data.shape[2]//2].unsqueeze(0)\n",
    "        elif idx:\n",
    "            print(f'using id {idx}')\n",
    "            slc = nru_dataset_shake[subj_idx][\"data\"][\"data\"][0,:,:,idx].unsqueeze(0)\n",
    "        else:\n",
    "            raise ValueError(\"Please specify idx or pos\")\n",
    "    return slc\n",
    "\n",
    "\n",
    "def load_slice_nru_nod(subj_idx, idx=None, pos=None, noise=None):\n",
    "    if noise:\n",
    "        if pos == 'middle':\n",
    "            print('using middle slice')\n",
    "            data = noise(nru_dataset_nod[subj_idx])[\"data\"][\"data\"][0,:,:,:]\n",
    "            slc = data[:,:,data.shape[2]//2].unsqueeze(0)\n",
    "        elif idx:\n",
    "            print(f'using id {idx}')\n",
    "            slc = noise(nru_dataset_nod[subj_idx])[\"data\"][\"data\"][0,:,:,idx].unsqueeze(0)\n",
    "        else:\n",
    "            raise ValueError(\"Please specify idx or pos\")\n",
    "    else:\n",
    "        if pos == 'middle':\n",
    "            print('using middle slice')\n",
    "            data = nru_dataset_nod[subj_idx][\"data\"][\"data\"][0,:,:,:]\n",
    "            slc = data[:,:,data.shape[2]//2].unsqueeze(0)\n",
    "        elif idx:\n",
    "            print(f'using id {idx}')\n",
    "            slc = nru_dataset_nod[subj_idx][\"data\"][\"data\"][0,:,:,idx].unsqueeze(0)\n",
    "        else:\n",
    "            raise ValueError(\"Please specify idx or pos\")\n",
    "    return slc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac94d13",
   "metadata": {},
   "source": [
    "Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "protecting-rainbow",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimCLR.load_from_checkpoint(\"/home/raecker1/3DSSL/weights/first_wat_crop_02TO1/checkpoints/epoch=372-step=5287275.ckpt\")\n",
    "#model = SimCLR.load_from_checkpoint(\"/home/raecker1/3DSSL/weights/first_wat_crop_075TO1/checkpoints/epoch=241-step=3430350.ckpt\")\n",
    "#model = SimCLR.load_from_checkpoint(\"/home/raecker1/3DSSL/weights/version_4/checkpoints/epoch=892-step=12658275.ckpt\")\n",
    "#model = SimCLR.load_from_checkpoint(\"/home/raecker1/3DSSL/weights/version_5/checkpoints/epoch=217-step=3090150.ckpt\")\n",
    "#model = SimCLR.load_from_checkpoint(\"/home/raecker1/3DSSL/weights/version_8/checkpoints/epoch=179-step=5103000.ckpt\")\n",
    "\n",
    "device = torch.device(\"cuda:0\")\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f879dae",
   "metadata": {},
   "source": [
    "Experiment: UKB (20 reference scans, similar height + weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "579b62c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_id = 25\n",
    "slc = 250\n",
    "reference_keys = pd.read_csv('/home/raecker1/3DSSL/selfsupervised2d/QualityControlExperiments/ref_keys.csv')\n",
    "root_path = '/mnt/qdata/share/rakuest1/data/UKB/raw/abdominal_MRI/raw/'\n",
    "ref_idx = []\n",
    "for subject in reference_keys['eid']:\n",
    "    path = Path(root_path)/str(subject)/\"wat.nii.gz\"\n",
    "    ref_idx.append(val_dataset.subjects_paths.index(path))\n",
    "\n",
    "noise = tio.Compose([tio.transforms.RandomNoise(mean=0, std=(0, 0.25))])\n",
    "sim_HQ = []\n",
    "sim_LQ = []\n",
    "for idx in ref_idx:\n",
    "    slice_test = load_slice(test_id, slc)\n",
    "    slice_HQ = load_slice(idx, slc)\n",
    "    slice_LQ = load_slice(idx, slc, noise)\n",
    "    feat_test = model(slice_test.unsqueeze(0).to(device))\n",
    "    feat_HQ = model(slice_HQ.unsqueeze(0).to(device))\n",
    "    feat_LQ = model(slice_LQ.unsqueeze(0).to(device))\n",
    "    sim_HQ.append(F.cosine_similarity(feat_test, feat_HQ))\n",
    "    sim_LQ.append(F.cosine_similarity(feat_test, feat_LQ))\n",
    "sim_HQ = torch.stack(sim_HQ).mean()\n",
    "sim_LQ = torch.stack(sim_LQ).mean()\n",
    "print(f'Mean similarity to HQ references: {sim_HQ}')\n",
    "print(f'Mean similarity to LQ reference: {sim_LQ}')\n",
    "plt.imshow(np.rot90(slice_test[0], 1), cmap='gray')\n",
    "plt.title(f'ID Noise: {test_id}, slice: {slc}, mean sim to HQ ref: {round(float(sim_HQ), 3)}/ LQ ref: {round(float(sim_LQ), 3)}')\n",
    "plt.savefig(f'/home/raecker1/3DSSL/selfsupervised2d/QualityControlExperiments/results/test_fig_meansim_randomnoise_new_id{test_id}_slc{slc}.png')\n",
    "plt.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b183781",
   "metadata": {},
   "source": [
    "Experiment: NAKO IQA (5 reference images, with and without image registration of reference scans to test scan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9331c297",
   "metadata": {},
   "outputs": [],
   "source": [
    "def warp_2D(img, flow):\n",
    "    flow = flow.astype('float32')\n",
    "    height, width = np.shape(img)[0], np.shape(img)[1]\n",
    "    posx, posy = np.mgrid[:height, :width]\n",
    "    # flow=np.reshape(flow, [-1, 3])\n",
    "    vx = flow[:, :, 1]  # to make it consistent as in matlab, ux in python is uy in matlab\n",
    "    vy = flow[:, :, 0]\n",
    "    coord_x = posx + vx\n",
    "    coord_y = posy + vy\n",
    "    coords = np.array([coord_x, coord_y])\n",
    "    if img.dtype == np.complex128:\n",
    "        img_real = np.real(img).astype('float32')\n",
    "        img_imag = np.imag(img).astype('float32')\n",
    "        warped_real = warp(img_real, coords, order=1)\n",
    "        warped_imag = warp(img_imag, coords, order=1)\n",
    "        warped = warped_real + 1j*warped_imag\n",
    "    else:\n",
    "        img = img.astype('float32')\n",
    "        warped = warp(img, coords, order=1)  # order=1 for bi-linear\n",
    "\n",
    "    return warped\n",
    "\n",
    "test_id = 16\n",
    "slc = 100\n",
    "registration = False\n",
    "\n",
    "ref_idx = list(range(5))\n",
    "\n",
    "sim_HQ = []\n",
    "sim_LQ = []\n",
    "for idx in ref_idx:\n",
    "    # load test slice\n",
    "    slc_test = load_slice_nako(test_id, slc)\n",
    "    #slc_test = load_slice_nako_deep(test_id, slc)\n",
    "    \n",
    "    # load reference slices\n",
    "    noise = tio.Compose([tio.transforms.RandomNoise(mean=0, std=(0, 0.7))])\n",
    "    #motion = tio.Motion(degrees=np.array([[2.5, 2.5, 2.5]]), translation=np.array([[2.5, 2.5, 2.5]]), times=np.array([0.5]), image_interpolation='linear')\n",
    "    motion = tio.Compose([tio.transforms.RandomMotion(num_transforms=1)])\n",
    "\n",
    "    slc_HQ = load_slice_nako(idx, slc)\n",
    "    slc_LQ = load_slice_nako(idx, slc, motion)\n",
    "    #slc_LQ = load_slice_nako_deep(idx, slc)\n",
    "    if registration:\n",
    "        slc_test = np.squeeze(slc_test.numpy())\n",
    "        slc_HQ = np.squeeze(slc_HQ.numpy())\n",
    "        slc_LQ = np.squeeze(slc_LQ.numpy())\n",
    "        \n",
    "        # flow calculation HQ (mov) to test (fix)\n",
    "        \n",
    "        ux, uy = optical_flow_tvl1(slc_test, slc_HQ)\n",
    "        flows = np.stack([ux, uy], axis=-1)\n",
    "        slc_HQ_warped = warp_2D(slc_HQ, flows)\n",
    "        slc_HQ = torch.from_numpy(slc_HQ_warped).unsqueeze(0)\n",
    "\n",
    "        # flow calculation LQ (mov) to test (fix)\n",
    "        ux, uy = optical_flow_tvl1(slc_test, slc_LQ)\n",
    "        flows = np.stack([ux, uy], axis=-1)\n",
    "        slc_LQ_warped = warp_2D(slc_LQ, flows)\n",
    "        slc_LQ = torch.from_numpy(slc_LQ_warped).unsqueeze(0)\n",
    "\n",
    "        slc_test = torch.from_numpy(slc_test).unsqueeze(0)\n",
    "    \n",
    "    # compute feature representations\n",
    "    feat_test = model(slc_test.unsqueeze(0).to(device))\n",
    "    feat_HQ = model(slc_HQ.unsqueeze(0).to(device))\n",
    "    feat_LQ = model(slc_LQ.unsqueeze(0).to(device))\n",
    "\n",
    "    # compute cosine similarity\n",
    "    sim_HQ.append(F.cosine_similarity(feat_test, feat_HQ))\n",
    "    sim_LQ.append(F.cosine_similarity(feat_test, feat_LQ))\n",
    "print(sim_HQ)\n",
    "print(sim_LQ)\n",
    "sim_HQ = torch.stack(sim_HQ).mean()\n",
    "sim_LQ = torch.stack(sim_LQ).mean()\n",
    "print(f'Mean similarity to HQ references: {sim_HQ}')\n",
    "print(f'Mean similarity to LQ reference: {sim_LQ}')\n",
    "plt.imshow(np.rot90(slc_test[0], 1), cmap='gray')\n",
    "plt.title(f'NAKO IQA BH ID: {test_id}, slice: {slc}, mean sim to HQ ref: {round(float(sim_HQ), 3)}/ LQ ref: {round(float(sim_LQ), 3)}')\n",
    "plt.show()\n",
    "plt.savefig(f'/home/raecker1/3DSSL/selfsupervised2d/QualityControlExperiments/results/fig_meansim_nakoiqa_fb_id{test_id}_slc{slc}.png')\n",
    "plt.close()\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef28dec",
   "metadata": {},
   "source": [
    "Experiment: NRU Brain Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2888ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "patients = range(5, 22)\n",
    "slc = 0\n",
    "ref_idx = list(range(5))\n",
    "sim_scores = {'LQ': [], 'HQ': []}\n",
    "for test_id in patients:\n",
    "    sim_HQ = []\n",
    "    sim_LQ = []\n",
    "    for idx in ref_idx:\n",
    "        slice_test = load_slice_nru_still(test_id, idx=150)\n",
    "        slice_HQ = load_slice_nru_still(idx, idx=150)\n",
    "        slice_LQ = load_slice_nru_nod(idx, idx=150)\n",
    "        feat_test = model(slice_test.unsqueeze(0).to(device))\n",
    "        feat_HQ = model(slice_HQ.unsqueeze(0).to(device))\n",
    "        feat_LQ = model(slice_LQ.unsqueeze(0).to(device))\n",
    "        sim_HQ.append(F.cosine_similarity(feat_test, feat_HQ))\n",
    "        sim_LQ.append(F.cosine_similarity(feat_test, feat_LQ))\n",
    "    sim_HQ = torch.stack(sim_HQ).mean()\n",
    "    sim_LQ = torch.stack(sim_LQ).mean()\n",
    "    sim_HQ = sim_HQ.cpu().detach().numpy()\n",
    "    sim_LQ = sim_LQ.cpu().detach().numpy()\n",
    "    sim_scores['HQ'].append(float(sim_HQ))\n",
    "    sim_scores['LQ'].append(float(sim_LQ))\n",
    "    print(f'Mean similarity to HQ references: {sim_HQ}')\n",
    "    print(f'Mean similarity to LQ reference: {sim_LQ}')\n",
    "    plt.imshow(np.rot90(slice_test[0], 1), cmap='gray')\n",
    "    plt.title(f'NRU t1stir nod still ID: {test_id}, slice: {slc}, mean sim to HQ ref: {round(float(sim_HQ), 3)}/ LQ ref: {round(float(sim_LQ), 3)}')\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "print(sim_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "578a5e9d",
   "metadata": {},
   "source": [
    "Experiment: Increasing Motion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ae96b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_id = 64\n",
    "reference_keys = pd.read_csv('/home/raecker1/3DSSL/selfsupervised2d/QualityControlExperiments/ref_keys.csv')\n",
    "root_path = '/mnt/qdata/share/rakuest1/data/UKB/raw/abdominal_MRI/raw/'\n",
    "ref_idx = []\n",
    "for subject in reference_keys['eid']:\n",
    "    path = Path(root_path)/str(subject)/\"wat.nii.gz\"\n",
    "    ref_idx.append(val_dataset.subjects_paths.index(path))\n",
    "slc = 265\n",
    "\n",
    "noise = tio.Compose([tio.transforms.RandomNoise(mean=0, std=(0, 0.5))])\n",
    "#noise = tio.Compose([tio.transforms.RandomNoise(mean=0, std=(0, 0.5))])\n",
    "#motion_lq = tio.Compose([tio.transforms.RandomMotion(num_transforms=1)])\n",
    "\n",
    "\n",
    "motion_1 = tio.Motion(degrees=np.array([[0.0, 0.0, 0.0]]), translation=np.array([[0.0, 0.0, 0.0]]),\n",
    "                      times=np.array([0.5]), image_interpolation='linear')\n",
    "motion_2 = tio.Motion(degrees=np.array([[0.5, 0.5, 0.5]]), translation=np.array([[0.5, 0.5, 0.5]]),\n",
    "                      times=np.array([0.5]), image_interpolation='linear')\n",
    "motion_3 = tio.Motion(degrees=np.array([[1.0, 1.0, 1.0]]), translation=np.array([[1.0, 1.0, 1.0]]),\n",
    "                      times=np.array([0.5]), image_interpolation='linear')\n",
    "motion_4 = tio.Motion(degrees=np.array([[1.5, 1.5, 1.5]]), translation=np.array([[1.5, 1.5, 1.5]]),\n",
    "                      times=np.array([0.5]), image_interpolation='linear')\n",
    "motion_5 = tio.Motion(degrees=np.array([[2.0, 2.0, 2.0]]), translation=np.array([[2.0, 2.0, 2.0]]),\n",
    "                      times=np.array([0.5]), image_interpolation='linear')\n",
    "motion_6 = tio.Motion(degrees=np.array([[2.5, 2.5, 2.5]]), translation=np.array([[2.5, 2.5, 2.5]]),\n",
    "                      times=np.array([0.5]), image_interpolation='linear')\n",
    "motion_7 = tio.Motion(degrees=np.array([[3.0, 3.0, 3.0]]), translation=np.array([[3.0, 3.0, 3.0]]),\n",
    "                      times=np.array([0.5]), image_interpolation='linear')\n",
    "\n",
    "motion_list = [motion_1, motion_2, motion_3, motion_4, motion_5, motion_6, motion_7]\n",
    "\n",
    "fig, axs = plt.subplots(1, len(motion_list), figsize=(35, 5))\n",
    "for i, motion in enumerate(motion_list):\n",
    "    sim_HQ = []\n",
    "    sim_LQ = []\n",
    "    for idx in tqdm(ref_idx):\n",
    "        slice_test = load_slice(test_id, slc, motion)\n",
    "        slice_HQ = load_slice(idx, slc)\n",
    "        slice_LQ = load_slice(idx, slc, noise)\n",
    "        feat_test = model(slice_test.unsqueeze(0).to(device))\n",
    "        feat_HQ = model(slice_HQ.unsqueeze(0).to(device))\n",
    "        feat_LQ = model(slice_LQ.unsqueeze(0).to(device))\n",
    "        sim_HQ.append(F.cosine_similarity(feat_test, feat_HQ))\n",
    "        sim_LQ.append(F.cosine_similarity(feat_test, feat_LQ))\n",
    "    sim_HQ = torch.stack(sim_HQ).mean()\n",
    "    sim_LQ = torch.stack(sim_LQ).mean()\n",
    "    print(f'Mean similarity to HQ references: {sim_HQ}')\n",
    "    print(f'Mean similarity to LQ reference: {sim_LQ}')\n",
    "    axs[i].imshow(np.rot90(slice_test[0], 1), cmap='gray')\n",
    "    axs[i].set_title(f'Motion {i}: sim HQ: {round(float(sim_HQ), 3)}/ sim LQ: {round(float(sim_LQ), 3)}')\n",
    "    axs[i].axis('off')\n",
    "\n",
    "plt.savefig('/mnt/qdata/share/raecker1/motion_sim_version8.png')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5059f041",
   "metadata": {},
   "source": [
    "Experiment: Increasing Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf69381b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_id = 64\n",
    "ref_idc = [1, 2, 3, 4, 5]\n",
    "\n",
    "noise_test = tio.Noise(mean=0.0, std=0.3, seed=29)\n",
    "noise_1 = tio.Noise(mean=0.0, std=0.1, seed=29)\n",
    "noise_2 = tio.Noise(mean=0.0, std=0.2, seed=29)\n",
    "noise_3 = tio.Noise(mean=0.0, std=0.3, seed=29)\n",
    "noise_4 = tio.Noise(mean=0.0, std=0.4, seed=29)\n",
    "                      \n",
    "\n",
    "#ref_motion_list = ['_', motion_1, motion_2, motion_3, motion_4]\n",
    "ref_noise_list = ['_', noise_1, noise_2, noise_3, noise_4]\n",
    "\n",
    "slc = 100\n",
    "slice_test = load_slice(test_id, slc, noise_test)\n",
    "feat_test = model(slice_test.unsqueeze(0).to(device))\n",
    "sim = {}\n",
    "for Q, noise in enumerate(ref_noise_list):\n",
    "    sim[f'Q{Q+1}'] = []\n",
    "    for ref_id in ref_idc:\n",
    "        if noise == '_':\n",
    "            slice_ref = load_slice(ref_id, slc)\n",
    "            slice_ref_sub = torch.sub(slice_ref, slice_ref)\n",
    "        else:\n",
    "            slice_ref = load_slice(ref_id, slc)\n",
    "            slice_ref_noise = load_slice(ref_id, slc, noise)\n",
    "            slice_ref_sub = torch.sub(slice_ref_noise, slice_ref)\n",
    "        feat_ref = model(slice_ref_sub.unsqueeze(0).to(device))\n",
    "        sim[f'Q{Q+1}'].append(F.cosine_similarity(feat_test, feat_ref))\n",
    "    sim[f'Q{Q+1}'] = torch.stack(sim[f'Q{Q+1}']).mean()\n",
    "\n",
    "plt.show()\n",
    "plt.imshow(np.rot90(slice_test[0], 1))\n",
    "plt.title(f'UKB ID sub noise Q1 groups: {test_id}, slice: {slc}, sim to Q1: {round(float(sim[\"Q1\"]), 3)}, Q2: {round(float(sim[\"Q2\"]), 3)}, Q3: {round(float(sim[\"Q3\"]), 3)}, Q4: {round(float(sim[\"Q4\"]), 3)}, Q5: {round(float(sim[\"Q5\"]), 3)}')\n",
    "plt.show()    \n",
    "#plt.savefig(f'/home/raecker1/3DSSL/selfsupervised2d/QualityControlExperiments/results/test_classification_{test_id}_slc{slc}.png')\n",
    "plt.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iqa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
